{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymongo as pm\n",
    "import csv\n",
    "import os\n",
    "import pprint\n",
    "import warnings\n",
    "import scipy\n",
    "import copy\n",
    "import pprint\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0542f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_add = \"<Your DB Address>\"\n",
    "auth_source = \"<Auth Source>\"\n",
    "username = \"<Your Username>\"\n",
    "password = \"<Your Password>\"\n",
    "\n",
    "client=pm.MongoClient(db_add,\n",
    "                      ssl=True,\n",
    "                      username=username,\n",
    "                      password=password,\n",
    "                      authSource = auth_source,\n",
    "                      authMechanism='SCRAM-SHA-1',\n",
    "                      tlsAllowInvalidCertificates = True\n",
    "                     )\n",
    "\n",
    "db = client['carsharing'] #choosing DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efefb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ActiveBookings =db['ActiveBookings']\n",
    "ActiveParkings = db['ActiveParkings']\n",
    "\n",
    "PermanentBookings =db['PermanentBookings']\n",
    "PermanentParkings =db['PermanentParkings']\n",
    "\n",
    "enjoy_ActiveBookings = db['enjoy_ActiveBookings']\n",
    "enjoy_ActiveParkings = db['enjoy_ActiveParkings']\n",
    "\n",
    "enjoy_PermanentBookings = db['enjoy_PermanentBookings']\n",
    "enjoy_PermanentParkings = db['enjoy_PermanentParkings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = [\"Berlin\",\"Firenze\",\"Toronto\"]\n",
    "jan2018_start=int('1514764800')\n",
    "jan2018_end=int('1517439600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Number of Rentals ##########################\n",
    "\n",
    "for c,city in enumerate(cities):\n",
    "    bookings = PermanentBookings\n",
    "    bookings = bookings.aggregate([\n",
    "    {\"$match\": # Matches city for January\n",
    "      {\"$and\": [{\"city\": city},\n",
    "                {\"init_time\": {\"$gte\": jan2018_start}},\n",
    "                {\"init_time\": {\"$lte\": jan2018_end}}\n",
    "                ]}\n",
    "      },\n",
    "    {\"$project\": {         \n",
    "        \"_id\": 0,\n",
    "        \"moved\": {\"$ne\": [{\"$arrayElemAt\": [\"$origin_destination.coordinates\", 0]},\n",
    "        {\"$arrayElemAt\": [\"$origin_destination.coordinates\", 1]}]},\n",
    "        \"bookingDuration\": {\"$subtract\": [\"$final_time\", \"$init_time\"]},\n",
    "        \"init_time\" : [\"$init_time\"]\n",
    "        }\n",
    "      },\n",
    "    {\"$match\": # Cars that moved and have booking duration more than 2 minutes and less than 3 hours\n",
    "            {\"$and\": [{\"moved\": True},\n",
    "            {\"bookingDuration\": {\"$gte\": 120}},\n",
    "            {\"bookingDuration\": {\"$lte\": 10800}}\n",
    "            ]}\n",
    "      }\n",
    "            ])\n",
    "    \n",
    "    temp=[]\n",
    "    for booking in bookings:\n",
    "        temp.append(booking)\n",
    "    sortedBookings = sorted(temp, key = lambda i: i['init_time'][0])\n",
    "    \n",
    "    totHours = []\n",
    "    for i in range(len(sortedBookings)):\n",
    "        totHours.append(sortedBookings[i]['init_time'][0])\n",
    "        \n",
    "    counter=0\n",
    "    counterPerHour = []\n",
    "    out={}\n",
    "    for i in range(0,744):\n",
    "        init = (jan2018_start + (3600*i))\n",
    "        end =  (init+3600)\n",
    "        for j in totHours:\n",
    "            if (j >= init and j < end):\n",
    "                counter+=1\n",
    "                out[i] = {}\n",
    "\n",
    "        counterPerHour.append(counter)\n",
    "        out[i] = {'unixTime': init,'hour': i, 'numberOfbookings': counter}\n",
    "        counter = 0\n",
    "        \n",
    "    with open(f'Rentals_{c}.csv', 'w') as outfile:\n",
    "        fields = ['unixTime', 'hour','numberOfbookings']\n",
    "        write = csv.DictWriter(outfile, fieldnames=fields) \n",
    "        write.writeheader()\n",
    "        for item in out.values():\n",
    "            write.writerow(item)\n",
    "            \n",
    "    fig = plt.figure(1, figsize=(12, 6))\n",
    "    x = np.linspace(1, 31, len(counterPerHour))\n",
    "    plt.xticks(np.arange(32))\n",
    "    plt.plot(x,counterPerHour,label=city)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Number of Bookings\")\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31eb49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################## Missing values management ##########################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    titles = os.listdir()\n",
    "    \n",
    "    #import cvs files\n",
    "    for title in titles:\n",
    "        if 'Rentals' in title:\n",
    "            _ , title = title.replace('.csv','').split('_')\n",
    "            title=int(title)\n",
    "            if title == 0:\n",
    "                title='Berlin'\n",
    "                timeSeries = pd.read_csv('Rentals_0.csv')\n",
    "                \n",
    "            elif title == 1:\n",
    "                title = \"Firenze\"\n",
    "                timeSeries = pd.read_csv('Rentals_1.csv')\n",
    "                \n",
    "            elif title == 2:\n",
    "                title = \"Toronto\"\n",
    "                timeSeries = pd.read_csv('Rentals_2.csv')\n",
    "                \n",
    "            container=[]\n",
    "            temp = 0\n",
    "            \n",
    "            # Check whether there are missing values and replace with 3 previous and next value's average which are non-zero\n",
    "            timeSeries2=timeSeries.copy()\n",
    "            for i in range(len(timeSeries2)-1):\n",
    "                now = timeSeries2.iloc[i]['numberOfbookings']\n",
    "                if now == 0:\n",
    "                    temp+=1\n",
    "                    if temp == 3:\n",
    "                        for j in range(3):\n",
    "                            container.append(timeSeries2.iloc[i-j-3]['numberOfbookings'])\n",
    "                elif now !=0 and temp >= 3:\n",
    "                    for j in range(3):\n",
    "                        container.append(timeSeries2.iloc[i+j]['numberOfbookings'])\n",
    "                        timeSeries2['numberOfbookings'][i-temp:i-1]=int(np.mean(container))\n",
    "                        temp = 0\n",
    "                        container=[]\n",
    "\n",
    "            comparison = pd.DataFrame.equals(timeSeries2,timeSeries)\n",
    "            timeSeries2['unixTime'] = pd.to_datetime(timeSeries2['unixTime'],infer_datetime_format=True,unit='s')\n",
    "            indexedTimeSeries = timeSeries2.set_index(['hour'])\n",
    "\n",
    "            # Plot time series\n",
    "            fig = plt.figure(1, figsize=(12, 6))\n",
    "            plt.grid(True)\n",
    "            plt.plot(indexedTimeSeries['numberOfbookings'])\n",
    "            plt.title(f'{title} - Missing data replaced')\n",
    "            plt.xlabel('Time (hour)')\n",
    "            plt.ylabel('Number of bookings')\n",
    "            plt.savefig(f'{title} - Missing data replaced.jpg')\n",
    "            plt.show()\n",
    "\n",
    "            if comparison:\n",
    "                print(f\"No missing value found for {title}\\n\\n\")\n",
    "            indexedTimeSeries.to_csv(f'timeSeries_{title}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888656a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################## Stationary check ##########################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    titles = os.listdir()\n",
    "    \n",
    "    # Import cvs files\n",
    "    for title in titles:\n",
    "        if '.csv' in title:\n",
    "            timeSeries = pd.read_csv(title)\n",
    "            \n",
    "            timeSeries = timeSeries.set_index(['hour'])\n",
    "            timeSeries = timeSeries.drop('unixTime',axis=1)\n",
    "            rolemean = timeSeries.rolling(window=24).mean()\n",
    "            rolestd = timeSeries.rolling(window=24).std()\n",
    "            print(rolemean,rolestd)\n",
    "            \n",
    "            # Rolling-statistics\n",
    "            fig = plt.figure(1, figsize=(12, 6))\n",
    "            original=plt.plot(timeSeries,color=\"blue\",label=\"Original\")\n",
    "            mean=plt.plot(rolemean,color=\"red\",label=\"Rolling Mean\")\n",
    "            std = plt.plot(rolestd, color=\"black\", label=\"Rolling std\")\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Time (hour)')\n",
    "            plt.ylabel('Number of bookings')\n",
    "            plt.legend(loc='best')\n",
    "            city = title.replace('.csv','').split('_')\n",
    "            plt.title(f'Rolling mean & standard deviation - {city}')\n",
    "            plt.savefig(f'Rolling mean & standard deviation - {city}.jpg', dpi = 600)\n",
    "            plt.show(block=False)\n",
    "            \n",
    "            # Dicky-Fuller test\n",
    "            dftest = adfuller(timeSeries['numberOfbookings'],autolag='AIC')\n",
    "            dfoutput= pd.Series(dftest[0:4],index=['Test Statistic','p-value','#Lags Used','Number of Observations'])\n",
    "            \n",
    "            for key,value in dftest[4].items():\n",
    "                dfoutput[f'Critical value {key}'] = value\n",
    "            print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Convert Unix time to the Data for Berlin ##########################\n",
    "\n",
    "series = pd.read_csv('Rentals_0.csv')\n",
    "series_copy = copy.copy(series)\n",
    "series_copy = series_copy.drop(series_copy.columns[1], axis=1)\n",
    "series_copy.dropna(axis=0)\n",
    "print(series)\n",
    "series_copy['unixTime'] = pd.to_datetime(series_copy['unixTime'], unit='s')\n",
    "print(\"Coverted Uninx time for Berlin\", series_copy)\n",
    "series_copy.to_csv(\"Berlin.csv\", sep='\\t', encoding='utf-8')\n",
    "\n",
    "########################## Convert Unix time to the Data for Firenze ##########################\n",
    "\n",
    "series2 = pd.read_csv('Rentals_1.csv')\n",
    "series_copy2 = copy.copy(series2)\n",
    "series_copy2 = series_copy2.drop(series_copy2.columns[1], axis=1)\n",
    "series_copy2.dropna(axis=0)\n",
    "print(series2)\n",
    "series_copy2['unixTime'] = pd.to_datetime(series_copy2['unixTime'],unit='s')\n",
    "print(\"Coverted Uninx time for Firenze\", series_copy2)\n",
    "series_copy2.to_csv(\"Firenze.csv\",sep='\\t', encoding='utf-8')\n",
    "\n",
    "########################## Convert Unix time to the Data for Toronto ##########################\n",
    "\n",
    "series3 = pd.read_csv('Rentals_2.csv')\n",
    "series_copy3 = copy.copy(series3)\n",
    "series_copy3 = series_copy3.drop(series_copy3.columns[1], axis=1)\n",
    "series_copy3.dropna(axis=0)\n",
    "print(series3)\n",
    "series_copy3['unixTime'] = pd.to_datetime(series_copy3['unixTime'],unit='s')\n",
    "print(\"Coverted Uninx time for Toronto\", series_copy3)\n",
    "series_copy3.to_csv(\"Toronto.csv\",sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab35f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################## ACF-PACF computation ##########################\n",
    "\n",
    "######### Plotting for Berlin #########\n",
    "df = pd.read_csv(\"timeSeries_Berlin.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "print(df)\n",
    "plt.figure(figsize=(8,8))\n",
    "pd.plotting.autocorrelation_plot(df.numberOfbookings)\n",
    "plt.title('Berlin AutoCorrelation')\n",
    "plt.savefig('Berlin AutoCorrelation.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1)\n",
    "plot_acf(df.numberOfbookings, ax = ax1, lags = 50)\n",
    "plt.title('Berlin ACF zoom')\n",
    "fig1.set_size_inches(8, 8)\n",
    "plt.savefig('Berlin ACF zoom.png', dpi=300)\n",
    "\n",
    "fig2, ax2 = plt.subplots( 1, 1)\n",
    "plot_pacf(df.numberOfbookings, ax = ax2, lags = 50 )\n",
    "plt.title('Berlin PACF')\n",
    "fig2.set_size_inches(8, 8)\n",
    "plt.savefig('Berlin PACF.png', dpi=300)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "######### Plotting for Firenze #########\n",
    "df = pd.read_csv(\"timeSeries_Firenze.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "plt.figure(figsize=(8,8))\n",
    "pd.plotting.autocorrelation_plot(df.numberOfbookings)\n",
    "plt.title('Firenze AutoCorrelation')\n",
    "plt.savefig('Firenze AutoCorrelation.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1)\n",
    "plot_acf(df.numberOfbookings, ax = ax1, lags = 50)\n",
    "plt.title('Firenze ACF zoom')\n",
    "fig1.set_size_inches(8, 8)\n",
    "plt.savefig('Firenze ACF zoom.png', dpi=300)\n",
    "\n",
    "fig2, ax2 = plt.subplots( 1, 1 )\n",
    "plot_pacf(df.numberOfbookings, ax = ax2, lags = 50 )\n",
    "plt.title('Firenze PACF')\n",
    "fig2.set_size_inches(8, 8)\n",
    "plt.savefig('Firenze PACF.png', dpi=300)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "######### Plotting for Toronto #########\n",
    "df = pd.read_csv(\"timeSeries_Toronto.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "plt.figure(figsize=(8,8))\n",
    "pd.plotting.autocorrelation_plot(df.numberOfbookings)\n",
    "plt.title('Toronto AutoCorrelation')\n",
    "plt.savefig('Toronto AutoCorrelation.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1)\n",
    "plot_acf(df.numberOfbookings, ax = ax1, lags = 50)\n",
    "plt.title('Toronto ACF zoom')\n",
    "fig1.set_size_inches(8, 8)\n",
    "plt.savefig('Toronto ACF zoom.png', dpi=600)\n",
    "\n",
    "fig2, ax2 = plt.subplots( 1, 1 )\n",
    "plot_pacf(df.numberOfbookings, ax = ax2, lags = 50 )\n",
    "plt.title('Toronto PACF')\n",
    "fig2.set_size_inches(8, 8)\n",
    "plt.savefig('Toronto PACF.png', dpi=600)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7df608",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Model training ##########################\n",
    "\n",
    "p = 3 # p=3 estimated from PACF, as if we had q=0\n",
    "q = 2 # More difficult to estimate, so we start with q=2\n",
    "d = 0 # The time series is stationary\n",
    "\n",
    "######### Plotting for Berlin #########\n",
    "df = pd.read_csv(\"timeSeries_Berlin.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "\n",
    "model = ARIMA(df.numberOfbookings,order=(p,d,q))\n",
    "model_fit = model.fit(disp=True)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.grid()\n",
    "plt.plot(df.numberOfbookings)\n",
    "plt.plot(model_fit.fittedvalues)\n",
    "plt.title(\"Real time series vs Predicted values - Berlin\")\n",
    "plt.legend([\"real time series\", \"predicted values\"])\n",
    "step_hours = np.arange(0, df.shape[0], step=24)\n",
    "step_ticks = df.iloc[step_hours][\"unixTime\"]\n",
    "plt.xticks(np.arange(df.shape[0], step=24), step_ticks, rotation=45)\n",
    "plt.xlabel(\"time [hours]\")\n",
    "plt.ylabel(\"number of rentals\")\n",
    "plt.savefig('OriginalPredicted_%s.png' % (\"Berlin\"))\n",
    "\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot(kind='kde', figsize=(15,5), grid=True, legend=False)\n",
    "\n",
    "plt.title(\"Residuals for Berlin\")\n",
    "plt.xlabel(\"residual errors\")\n",
    "plt.savefig('error_%s.png' % (\"Berlin\"))\n",
    "\n",
    "######### Plotting for Firenze #########\n",
    "df2 = pd.read_csv(\"timeSeries_Firenze.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "\n",
    "model2 = ARIMA(df2.numberOfbookings,order=(p,d,q))\n",
    "model_fit2 = model2.fit(disp=True)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.grid()\n",
    "plt.plot(df2.numberOfbookings)\n",
    "plt.plot(model_fit2.fittedvalues)\n",
    "plt.title(\"Real time series vs Predicted values - Firenze\")\n",
    "plt.legend([\"real time series\", \"predicted values\"])\n",
    "step_hours = np.arange(0, df2.shape[0], step=24)\n",
    "step_ticks = df2.iloc[step_hours][\"unixTime\"]\n",
    "plt.xticks(np.arange(df2.shape[0], step=24), step_ticks, rotation=45)\n",
    "plt.xlabel(\"time [hours]\")\n",
    "plt.ylabel(\"number of rentals\")\n",
    "plt.savefig('OriginalPredicted_%s.png' % (\"Firenze\"))\n",
    "\n",
    "residuals2 = pd.DataFrame(model_fit2.resid)\n",
    "residuals2.plot(kind='kde', figsize=(15,5), grid=True, legend=False)\n",
    "\n",
    "plt.title(\"Residuals for Firenze\")\n",
    "plt.xlabel(\"residual errors\")\n",
    "plt.savefig('error_%s.png' % (\"Firenze\"))\n",
    "\n",
    "######### Plotting for Toronto #########\n",
    "\n",
    "df3 = pd.read_csv(\"timeSeries_Toronto.csv\", usecols=['unixTime','numberOfbookings'])\n",
    "\n",
    "model3 = ARIMA(df3.numberOfbookings,order=(p,d,q))\n",
    "model_fit3 = model3.fit(disp=True)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.grid()\n",
    "plt.plot(df3.numberOfbookings)\n",
    "plt.plot(model_fit3.fittedvalues)\n",
    "plt.title(\"Real time series vs Predicted values - Toronto\")\n",
    "plt.legend([\"real time series\", \"predicted values\"])\n",
    "step_hours = np.arange(0, df3.shape[0], step=24)\n",
    "step_ticks = df3.iloc[step_hours][\"unixTime\"]\n",
    "plt.xticks(np.arange(df3.shape[0], step=24), step_ticks, rotation=45)\n",
    "plt.xlabel(\"time [hours]\")\n",
    "plt.ylabel(\"number of rentals\")\n",
    "plt.savefig('OriginalPredicted_%s.png' % (\"Toronto\"))\n",
    "\n",
    "residuals3 = pd.DataFrame(model_fit3.resid)\n",
    "residuals3.plot(kind='kde', figsize=(15,5), grid=True, legend=False)\n",
    "\n",
    "plt.title(\"Residuals for Toronto\")\n",
    "plt.xlabel(\"residual errors\")\n",
    "plt.savefig('error_%s.png' % (\"Toronto\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9096fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataparse (time_in_secs):\n",
    "    pd.datatime.fromtimestamp(float(time_in_secs))\n",
    "    \n",
    "df = pd.read_csv(\"timeSeries_Berlin.csv\", usecols=['hour','numberOfbookings'])\n",
    "df = df.rename(columns={'numberOfbookings':'rental','hour':'hour'})\n",
    "df.rental += np.random.random_sample(len(df.rental)) / 10.0\n",
    "\n",
    "df.hour -= df.hour[0]\n",
    "# Replace method:\n",
    "# [0] Replace with 0\n",
    "# [1] Replace with previous value\n",
    "# [2] Replace missing values assuming linear change\n",
    "replace_method = 2\n",
    "# Check missing values and print missing IDs\n",
    "missing = False\n",
    "\n",
    "for i in range(1,len(df)):\n",
    "    if not df['hour'][i] == df['hour'][i-1] + 1:\n",
    "        missing = True\n",
    "        print(\"%i => %f, %i => %f\" % (i-1,df['hour'][i-1],i,df['hour'][i]))\n",
    "        start = int(df['hour'][i-1] + 1)\n",
    "        end = int(df['hour'][i])\n",
    "        startR = df['rental'][i-1]\n",
    "        endR = df['rental'][i]\n",
    "        \n",
    "        deltaR = endR - startR\n",
    "        deltaRoverH = deltaR / (end - start + 2)\n",
    "        print (deltaRoverH)\n",
    "        \n",
    "        print(\"Missing hours from %i (%f) to %i (%f)\" % (start, startR, end, endR))\n",
    "        \n",
    "        p = 1\n",
    "        for k in range(start,end):\n",
    "            if replace_method == 0:\n",
    "                newval = 0\n",
    "            elif replace_method == 1:\n",
    "                newval = df['rental'][i-1]\n",
    "            elif replace_method == 2:\n",
    "                newval = startR + deltaRoverH * p\n",
    "            else:\n",
    "                print(\"Unknown replace method\")\n",
    "                \n",
    "            # Add random noise\n",
    "            newval = newval + np.random.random_sample() / 10.0\n",
    "            \n",
    "            df = df.append({ 'hour': k, 'rental' : newval }, ignore_index=True)\n",
    "            print(\"New row (%i,%.3f)\" % (k, newval))\n",
    "            p = p + 1\n",
    "            \n",
    "df = df.sort_values(by=['hour'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.plot(x = 'hour', y = 'rental', figsize=(15,5), title = \"Berlin\")\n",
    "X = df.rental.values.astype(float)\n",
    "\n",
    "# Define trainset size and window size\n",
    "size = 24*7*2\n",
    "test_len = 96\n",
    "\n",
    "p_values = [0, 1, 2, 3, 4, 6, 8, 10, 12]\n",
    "d_values = [0]\n",
    "q_values = [0, 1, 2, 3, 4]\n",
    "\n",
    "best_mse = float(\"inf\")\n",
    "best_r2 = -float(\"inf\")\n",
    "best_params = (0,0,0)\n",
    "\n",
    "r2_scores = pd.DataFrame(None, columns=list(map(lambda x: 'p='+str(x),p_values)), \n",
    "                         index=list(map(lambda x: 'q='+str(x),q_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cabf9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################## GRID SEARCH ##########################\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            print(\"Testing ARIMA model (%i,%i,%i)\" % (p,d,q))\n",
    "            # Split dataset into train and test\n",
    "            train, test = X[0:size], X[size:(size+test_len)]\n",
    "            \n",
    "            history = [x for x in train]\n",
    "            predictions = list()\n",
    "            try:\n",
    "                for t in range(0,test_len):\n",
    "                    model = ARIMA(history, order=(p,d,q))\n",
    "                    model_fit = model.fit(disp=0)\n",
    "                    output = model_fit.forecast()\n",
    "                    \n",
    "                    yhat = output[0]\n",
    "                    predictions.append(yhat)\n",
    "                    \n",
    "                    obs = test[t]\n",
    "                    history.append(obs)\n",
    "                    \n",
    "                    # Sliding window: remove first element\n",
    "                    history = history[1:]\n",
    "                    \n",
    "                mse = mean_squared_error(test, predictions)\n",
    "                \n",
    "                r2 = r2_score(test,predictions)\n",
    "                r2_scores['p='+str(p)]['q='+str(q)] = r2\n",
    "                print(\"R2\\t%f\" % r2)\n",
    "                if r2 > best_r2:\n",
    "                    best_r2 = r2\n",
    "                print(\"MSE\\t%f\" % mse)\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_params = (p,d,q)\n",
    "                    \n",
    "            except:\n",
    "                print(\"\\tError\")\n",
    "                continue\n",
    "                \n",
    "print(\"Best MSE %f with ARIMA(%i,%i,%i)\" % (best_mse, best_params[0], best_params[1], best_params[2]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## PLOT HEATMAP ##########################\n",
    "\n",
    "errors = pd.DataFrame(r2_scores.to_numpy(dtype=float),\n",
    "                      columns=list(map(lambda x: 'p='+str(x),p_values)),\n",
    "                      index=list(map(lambda x: 'q='+str(x),q_values)))\n",
    "\n",
    "grayscale = sns.cubehelix_palette(50, hue=1, rot=.5, light=.75, dark=.25, as_cmap=True)\n",
    "ax = sns.heatmap(errors, linewidth=1, center=(errors.max().max()-errors.min().min())/2, \n",
    "                 cmap=grayscale, vmin = errors.min().min(), vmax = errors.max().max(), annot=True)\n",
    "plt.savefig('heatmap_%s.png' % (\"Berlin\"), dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## TESTS WITH SLIDING WINDOW ##########################\n",
    "\n",
    "X = df.rental.values.astype(float)\n",
    "# Define trainset size\n",
    "sizes = range(3,22)# TWO WEEKS\n",
    "# How many times I shift the window\n",
    "test_len = 24*7\n",
    "p = 6\n",
    "d = 0\n",
    "q = 1\n",
    "r2_scores = []\n",
    "for days in sizes:\n",
    "    # Split dataset into train and test\n",
    "    size = days*24\n",
    "    train, test = X[0:size], X[size:(size+test_len)]\n",
    "    \n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    \n",
    "    for t in range(0,test_len):\n",
    "        try:\n",
    "            model = ARIMA(history, order=(p,d,q))\n",
    "            model_fit = model.fit(disp=0, maxiter=200)\n",
    "            output = model_fit.forecast()\n",
    "            \n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            \n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "            \n",
    "            # Sliding window\n",
    "            history = history[1:]\n",
    "            \n",
    "        except:\n",
    "            predictions.append(0)\n",
    "            \n",
    "    r2 = r2_score(test,predictions)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    print(\"R2\\t%f\" % r2)\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        \n",
    "    print(\"MSE\\t%f\" % mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_params = (p,d,q)\n",
    "        \n",
    "labels=['3d',None,'5d',None,'1w',None,None,None,None,None,None,'2w',None,None,None,None,None,None,'3w']\n",
    "indexes = []\n",
    "nsp = 0\n",
    "for label in labels:\n",
    "    if label == None:\n",
    "        nsp = nsp + 1\n",
    "        s = \"\"\n",
    "        for _ in range(0,nsp): s = s+\" \"\n",
    "        indexes.append(s)\n",
    "    else:\n",
    "        indexes.append(label)\n",
    "\n",
    "r2_df = pd.DataFrame(r2_scores,index=indexes)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.ylim((0,1))\n",
    "plt.plot(r2_df)\n",
    "plt.savefig('SLIDING_WINDOW.png')\n",
    "\n",
    "########################## TESTS WITH EXPANDING WINDOW ##########################\n",
    "\n",
    "X = df.rental.values.astype(float)\n",
    "sizes = range(3,22)\n",
    "test_len = 24*2 # 4 days\n",
    "p = 6\n",
    "d = 0\n",
    "q = 1\n",
    "\n",
    "r2_scores = []\n",
    "\n",
    "for days in sizes:\n",
    "    # Split dataset into train and test\n",
    "    \n",
    "    size = days*24\n",
    "    train, test = X[0:size], X[size:(size+test_len)]\n",
    "    \n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    \n",
    "    for t in range(0,test_len):\n",
    "        try:\n",
    "            model = ARIMA(history, order=(p,d,q))\n",
    "            model_fit = model.fit(disp=0, maxiter=200)\n",
    "            output = model_fit.forecast()\n",
    "            \n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            \n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "            #Expanding window!\n",
    "            \n",
    "        except:\n",
    "            predictions.append(0)\n",
    "            \n",
    "    mse = mean_squared_error(test, predictions)\n",
    "    r2 = r2_score(test,predictions)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    print(\"R2\\t%f\" % r2)\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        \n",
    "    print(\"MSE\\t%f\" % mse)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_params = (p,d,q)\n",
    "        \n",
    "labels=['3d',None,'5d',None,'1w',None,None,None,None,None,None,'2w',None,None,None,None,None,None,'3w']\n",
    "indexes = []\n",
    "nsp = 0\n",
    "for label in labels:\n",
    "    if label == None:\n",
    "        nsp = nsp + 1\n",
    "        s = \"\"\n",
    "        for _ in range(0,nsp): \n",
    "            s = s+\" \"\n",
    "        indexes.append(s)\n",
    "    else:\n",
    "        indexes.append(label)\n",
    "    \n",
    "df = pd.DataFrame(r2_scores,index=indexes)\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.ylim((0,1))\n",
    "plt.plot(r2_df)\n",
    "plt.savefig('EXPANDING_WINDOW.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
